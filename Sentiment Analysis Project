Sentiment Analysis project
Name student: Jorge Emilio Vasquez
Student ID: 300359443
Double-click (or enter) to edit


[3]
4s
!pip install nltk pandas numpy wordcloud matplotlib scikit-learn tensorflow keras

Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)
Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.4)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)
Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)
Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)
Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)
Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)
Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (11.0.0)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)
Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)
Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)
Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)
Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)
Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)
Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)
Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)
Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)
Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)
Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)
Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)
Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)
Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)
Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)
Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)
Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)
Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)
Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)
Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)
Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)
Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)
Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)
Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)
Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)
Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)
Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)

[ ]

[5]
0s
# Import required libraries
import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense
from keras.utils import to_categorical
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split


[ ]

Start coding or generate with AI.

[6]
0s
# Load the dataset
data = pd.read_csv("customer_review.tsv", sep="\t", encoding="iso-8859-1")

# Display the first 10 rows of the dataset
print(data.head(10))

   ï»¿rating       date             variation  \
0          5  31-Jul-18      Charcoal Fabric    
1          5  31-Jul-18      Charcoal Fabric    
2          4  31-Jul-18        Walnut Finish    
3          5  31-Jul-18      Charcoal Fabric    
4          5  31-Jul-18      Charcoal Fabric    
5          5  31-Jul-18  Heather Gray Fabric    
6          3  31-Jul-18     Sandstone Fabric    
7          5  31-Jul-18      Charcoal Fabric    
8          5  30-Jul-18  Heather Gray Fabric    
9          5  30-Jul-18  Heather Gray Fabric    

                                    verified_reviews  feedback  
0                                      Love my Echo!         1  
1                                          Loved it!         1  
2  Sometimes while playing a game, you can answer...         1  
3  I have had a lot of fun with this thing. My 4 ...         1  
4                                              Music         1  
5  I received the echo as a gift. I needed anothe...         1  
6  Without having a cellphone, I cannot use many ...         1  
7  I think this is the 5th one I've purchased. I'...         1  
8                                        looks great         1  
9  Love it! Iâve listened to songs I havenât ...         1  

[7]
0s
# Check for missing values
print("Missing values per column:\n", data.isnull().sum())

Missing values per column:
 ï»¿rating           0
date                0
variation           0
verified_reviews    1
feedback            0
dtype: int64

[12]
0s
# Rename columns if needed
data = data.rename(columns={"old_name1": "new_name1", "old_name2": "new_name2"})
print(data.columns)
print(data.head())

Index(['ï»¿rating', 'date', 'variation', 'verified_reviews', 'feedback'], dtype='object')
   ï»¿rating       date         variation  \
0          5  31-Jul-18  Charcoal Fabric    
1          5  31-Jul-18  Charcoal Fabric    
2          4  31-Jul-18    Walnut Finish    
3          5  31-Jul-18  Charcoal Fabric    
4          5  31-Jul-18  Charcoal Fabric    

                                    verified_reviews  feedback  
0                                      Love my Echo!         1  
1                                          Loved it!         1  
2  Sometimes while playing a game, you can answer...         1  
3  I have had a lot of fun with this thing. My 4 ...         1  
4                                              Music         1  

[15]
0s
print(clean_text("This is a test review."))
data.dropna(subset=['verified_reviews'], inplace=True) # dropping rows having NaN in 'verified_reviews' column

test review
Double-click (or enter) to edit


[16]
0s
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')  # Download stopwords if you haven't already

def clean_text(text):
    stopwords_list = set(stopwords.words("english"))
    # Lowercase text
    text = text.lower()
    # Remove numbers and special characters
    text = ''.join([char if char.isalnum() or char.isspace() else ' ' for char in text])
    # Remove stopwords
    text = ' '.join([word for word in text.split() if word not in stopwords_list])
    return text

# Call the function with a test string
test_string = "This is a test string with some punctuation and stopwords."
cleaned_string = clean_text(test_string)
print(cleaned_string)  # Should print the cleaned string

test string punctuation stopwords
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!

[17]
1s
data["clean_review"] = data["verified_reviews"].apply(clean_text)

[18]
2s
# Combine all reviews into a single string
all_reviews = " ".join(data["clean_review"])

# Generate word cloud
wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(all_reviews)

# Plot word cloud
plt.figure(figsize=(8, 8), facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.show()



[20]
0s
# Encode target labels
encoder = LabelEncoder()
data["encoded_sentiment"] = encoder.fit_transform(data["user_sentiment"])
# Display the dataset with encoded sentiments
print(data.head(10))


Next steps:

[ ]
# Tokenize and vectorize reviews
tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts(data["clean_review"])
X = tokenizer.texts_to_sequences(data["clean_review"])
X = pad_sequences(X, padding="post")

# Display tokenized reviews
print(X[:5])


[ ]
# One-hot encode the labels
Y = to_categorical(data["encoded_sentiment"])

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)


[ ]
# Define the model
model = Sequential([
    Embedding(input_dim=5000, output_dim=120, input_length=X.shape[1]),
    SpatialDropout1D(0.4),
    LSTM(176, dropout=0.2, recurrent_dropout=0.2),
    Dense(2, activation="softmax")
])

# Compile the model
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# Display model summary
model.summary()


[ ]
# Train the model
model.fit(X_train, y_train, epochs=5, batch_size=32, verbose="auto")


[ ]
# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {accuracy:.3f}")


[ ]
# Predict sentiments on the test set
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)

# Generate classification report
report = classification_report(y_true, y_pred, target_names=encoder.classes_)
print(report)


[ ]
# Client program for sentiment prediction
def predict_sentiment(review):
    # Clean the review
    cleaned_review = clean_text(review)
    # Tokenize and pad the review
    tokenized_review = tokenizer.texts_to_sequences([cleaned_review])
    padded_review = pad_sequences(tokenized_review, maxlen=X.shape[1], padding="post")
    # Predict sentiment
    sentiment = model.predict(padded_review)
    predicted_class = np.argmax(sentiment)
    return encoder.inverse_transform([predicted_class])[0]

# Test the client program
user_review = input("Enter a review: ")
predicted_sentiment = predict_sentiment(user_review)
print(f"Predicted Sentiment: {predicted_sentiment}")


[ ]
#Splitting the data into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)

print("Number of samples for training [news]:{}\nNumber of sample for training [Labels]:{}".format(X_train.shape,y_train.shape))
print("Number of samples for testing [news]:{}\nNumber of sample for testing [Labels]:{}".format(X_test.shape,y_test.shape))

[ ]
#define model
n_features = 41
model = Sequential()
model.add(Embedding(500,120,input_shape=(n_features,)))
model.add(Flatten())
model.add(Dense(10, activation='relu', kernel_initializer ='he_normal', input_shape=(n_features,)))
model.add(Dense(8, activation='relu', kernel_initializer ='he_normal'))
model.add(Dense(3, activation='sigmoid'))

/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)

[ ]
# compile the model

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'] )
# fit the model
model.fit(X_train,y_train,epochs=20, batch_size=32, verbose=2)

[ ]
# Evaluate out model using the accuracy metric
loss, acc = model.evaluate(X_test,y_test,verbose=0)
print('Test Accuracy: %.3f' % acc)

[ ]
# Evaluating the model
sentiment_prediction = model.predict(X_test)
predicted_inverse = np.argmax(sentiment_prediction,axis=1)
y_test_inverse = np.argmax(y_test,axis=1)

[ ]

Start coding or generate with AI.

[ ]
target_name = ["Class {}".format(i) for i in range(3)]

print(classification_report(y_test_inverse,predicted_inverse,target_names=target_name) )
              precision    recall  f1-score   support

     Class 0       0.50      0.35      0.41       122
     Class 1       0.72      0.85      0.78       565
     Class 2       0.58      0.45      0.51       282

    accuracy                           0.67       969
   macro avg       0.60      0.55      0.57       969
weighted avg       0.65      0.67      0.66       969
